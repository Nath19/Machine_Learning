{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Analytics Customer Revenue Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La règle des 80/20 s'est avérée vraie pour de nombreuses entreprises - seul un faible pourcentage de clients produit la majeure partie des revenus. Ainsi, les équipes de marketing sont mises au défi de faire les investissements appropriés dans les stratégies promotionnelles.\n",
    "Dans ce problème, nous sommes mis au défi d'analyser un ensemble de données client Google Merchandise Store (également connu sous le nom de GStore, où Google swag est vendu) pour prédire les revenus par client.\n",
    "\n",
    "L’objectif de ce projet était de prédire la somme des revenues de google par utilisateur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Fields\n",
    "- fullVisitorId- Identifiant unique pour chaque utilisateur du Google Merchandise Store.\n",
    "- channelGrouping - Chaîne par laquelle les utilisateurs passent pour accéder au Store.\n",
    "- date - Date à laquelle l’utilisateur a visité le store.\n",
    "- device - Spécificités de l’appareil que l’utilisateur a utilisé pour accéder au store.\n",
    "- geoNetwork - Cette section contient les informations géographiques de l’utilisateur.\n",
    "- sessionId - Un identifiant unique pour cette visite.\n",
    "- socialEngagementType - Type d’engagement, que ce soit un “engagé socialement” ou “Pas engagé socialement”.\n",
    "- totals - Cette section contient les valeurs agrégées de la session.\n",
    "- trafficSource - Cette section contient des informations sur la source de trafic à l'origine de la session.\n",
    "- visitId -Un identifiant pour cette session. Cela fait partie de la valeur généralement stockée en tant que cookie.\n",
    "- visitNumber -  Numéro de session de cet utilisateur. S'il s'agit de la première session, celle-ci est définie sur 1.\n",
    "- visitStartTime -  timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanamar/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning:\n",
      "\n",
      "Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as datetime\n",
    "from datetime import timedelta, date\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as CM\n",
    "from pandas.io.json import json_normalize\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "%matplotlib inline\n",
    "import math\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(path):\n",
    "    df = pd.read_csv(path, dtype={'fullVisitorId': 'str'})\n",
    "    json_columns = ['totals','trafficSource','device','geoNetwork']\n",
    "    for json_col in json_columns: \n",
    "        in_df = pd.DataFrame(df.pop(json_col).apply(pd.io.json.loads).values.tolist(), index=df.index)\n",
    "        df = df.join(in_df) \n",
    "     \n",
    "    #json columns of columns\n",
    "    in_df = pd.DataFrame(df.pop('adwordsClickInfo').values.tolist(), index=df.index)\n",
    "    df = df.join(in_df)     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation et analyse du train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'train.csv' does not exist: b'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a282cc3af571>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-22cc53cdc2cd>\u001b[0m in \u001b[0;36mload_df\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'fullVisitorId'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mjson_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'totals'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'trafficSource'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'geoNetwork'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mjson_col\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0min_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'train.csv' does not exist: b'train.csv'"
     ]
    }
   ],
   "source": [
    "train = load_df(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse et importation du test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_df(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on l'a vu avec le head il semble il y avoir bcp de NA, il serait interessant de savoir ou et combien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Faisons un plot en pourcentage répresentant combien et ou il y a des NA**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "miss_per = {}\n",
    "for k, v in dict(train.isna().sum(axis=0)).items():\n",
    "    if v == 0:\n",
    "        continue\n",
    "    miss_per[k] = 100 * float(v) / len(train)\n",
    "    \n",
    "import operator \n",
    "sorted_x = sorted(miss_per.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print (\"Il y a \" + str(len(miss_per)) + \" colonnes avec des valeurs manquantes\")\n",
    "\n",
    "kys = [_[0] for _ in sorted_x][::-1]\n",
    "vls = [_[1] for _ in sorted_x][::-1]\n",
    "trace1 = go.Bar(y = kys, orientation=\"h\" , x = vls, marker=dict(color=\"#d6a5ff\"))\n",
    "layout = go.Layout(title=\"Pourcentage de valeur manquante\", \n",
    "                   xaxis=dict(title=\"Pourcentage\"), \n",
    "                   height=400, margin=dict(l=300, r=300))\n",
    "figure = go.Figure(data = [trace1], layout = layout)\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remplacons tout les champs vide avec des NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train.replace('(not set)', np.nan)\n",
    "train.replace(\"not available in demo dataset\", np.nan)\n",
    "train.replace('(not provided)', np.nan)\n",
    "train.replace('unknown.unknown', np.nan)\n",
    "train.replace('(none)', np.nan)\n",
    "train.replace('/', np.nan)\n",
    "train.replace('Not Socially Engaged', np.nan)\n",
    "test.replace('(not set)', np.nan)\n",
    "test.replace(\"not available in demo dataset\", np.nan)\n",
    "test.replace('(not provided)', np.nan)\n",
    "test.replace('unknown.unknown', np.nan)\n",
    "test.replace('(none)', np.nan)\n",
    "test.replace('/', np.nan)\n",
    "test.replace('Not Socially Engaged', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Jetons un oeil au variable numeric du train et test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_train = train.select_dtypes(include=[np.number])\n",
    "numeric_features_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_test = test.select_dtypes(include=[np.number])\n",
    "numeric_features_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetons un oeil au variable catégorielle du train et test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_train = train.select_dtypes(include=[np.object])\n",
    "categorical_features_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_features_test = test.select_dtypes(include=[np.object])\n",
    "categorical_features_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des données et Analyses (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_cols = [\"browser\", \"deviceCategory\", \"operatingSystem\"]\n",
    "\n",
    "colors = [\"#d6a5ff\", \"#fca6da\", \"#f4d39c\", \"#a9fcca\"]\n",
    "traces = []\n",
    "for i, col in enumerate(device_cols):\n",
    "    t = train[col].value_counts()\n",
    "    traces.append(go.Bar(marker=dict(color=colors[i]),orientation=\"h\", y = t.index[:15][::-1], x = t.values[:15][::-1]))\n",
    "\n",
    "fig = tools.make_subplots(rows=1, cols=3, subplot_titles=[\"Visites: Categorie\", \"Visites: Navigateur\",\"Visites: OS\"], print_grid=False)\n",
    "fig.append_trace(traces[1], 1, 1)\n",
    "fig.append_trace(traces[0], 1, 2)\n",
    "fig.append_trace(traces[2], 1, 3)\n",
    "\n",
    "fig['layout'].update(height=400, showlegend=False, title=\"Visites par attributs de périphérique\")\n",
    "iplot(fig)\n",
    "\n",
    "## convert transaction revenue to float\n",
    "train[\"transactionRevenue\"] = train[\"transactionRevenue\"].astype('float')\n",
    "\n",
    "device_cols = [\"browser\", \"deviceCategory\", \"operatingSystem\"]\n",
    "\n",
    "fig = tools.make_subplots(rows=1, cols=3, subplot_titles=[\"Revenu moyen: Categorie\", \"Revenu moyen: Navigateur\",\"Revenu moyen: OS\"], print_grid=False)\n",
    "\n",
    "colors = [\"red\", \"green\", \"purple\"]\n",
    "trs = []\n",
    "for i, col in enumerate(device_cols):\n",
    "    tmp = train.groupby(col).agg({\"transactionRevenue\": \"mean\"}).reset_index().rename(columns={\"transactionRevenue\" : \"Mean Revenue\"})\n",
    "    tmp = tmp.dropna().sort_values(\"Mean Revenue\", ascending = False)\n",
    "    tr = go.Bar(x = tmp[\"Mean Revenue\"][::-1], orientation=\"h\", marker=dict(opacity=0.5, color=colors[i]), y = tmp[col][::-1])\n",
    "    trs.append(tr)\n",
    "\n",
    "fig.append_trace(trs[1], 1, 1)\n",
    "fig.append_trace(trs[0], 1, 2)\n",
    "fig.append_trace(trs[2], 1, 3)\n",
    "fig['layout'].update(height=400, showlegend=False, title=\"Revenu moyen par attribut d'appareil\")\n",
    "iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a une différence significative dans les visites depuis les mobiles et les tablettes, mais les revenus moyens pour les deux sont très proches. Il est intéressant de noter que le nombre maximal de visites provient du navigateur Chrome, mais que les revenus maximaux sont collectés grâce aux visites via Firefox. Les utilisateurs de Chrome OS ont généré des revenus maximaux, bien que le nombre maximal de visites proviennent d'utilisateurs Windows et Macintosh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo Network Attributes:\n",
    "\n",
    "Voyons quels sont tous les attributs de geoNetwork.\n",
    "\n",
    "Analysons la répartition des utilisateurs sur 5 continents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_cols = ['city', 'continent','country',\n",
    "            'metro', 'networkDomain', 'region','subContinent']\n",
    "geo_cols = ['continent','subContinent']\n",
    "\n",
    "colors = [\"#d6a5ff\", \"#fca6da\"]\n",
    "fig = tools.make_subplots(rows=1, cols=2, subplot_titles=[\"Visites : GeoNetwork Continent\", \"Visites : GeoNetwork subContinent\"], print_grid=False)\n",
    "trs = []\n",
    "for i,col in enumerate(geo_cols):\n",
    "    t = train[col].value_counts()\n",
    "    tr = go.Bar(x = t.index[:20], marker=dict(color=colors[i]), y = t.values[:20])\n",
    "    trs.append(tr)\n",
    "\n",
    "fig.append_trace(trs[0], 1, 1)\n",
    "fig.append_trace(trs[1], 1, 2)\n",
    "fig['layout'].update(height=400, margin=dict(b=150), showlegend=False)\n",
    "iplot(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "geo_cols = ['continent','subContinent']\n",
    "fig = tools.make_subplots(rows=1, cols=2, subplot_titles=[\"Revenu moyen: Continent\", \"Revenu moyen: SubContinent\"], print_grid=False)\n",
    "\n",
    "colors = [\"blue\", \"orange\"]\n",
    "trs = []\n",
    "for i, col in enumerate(geo_cols):\n",
    "    tmp = train.groupby(col).agg({\"transactionRevenue\": \"mean\"}).reset_index().rename(columns={\"transactionRevenue\" : \"Mean Revenue\"})\n",
    "    tmp = tmp.dropna().sort_values(\"Mean Revenue\", ascending = False)\n",
    "    tr = go.Bar(y = tmp[\"Mean Revenue\"], orientation=\"v\", marker=dict(opacity=0.5, color=colors[i]), x= tmp[col])\n",
    "    trs.append(tr)\n",
    "\n",
    "fig.append_trace(trs[0], 1, 1)\n",
    "fig.append_trace(trs[1], 1, 2)\n",
    "fig['layout'].update(height=450, margin=dict(b=200), showlegend=False)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir avec une meilleur visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colorscale = [[0, 'rgb(102,194,165)'], [0.0005, 'rgb(102,194,165)'], \n",
    "              [0.01, 'rgb(171,221,164)'], [0.02, 'rgb(230,245,152)'], \n",
    "              [0.04, 'rgb(255,255,191)'], [0.05, 'rgb(254,224,139)'], \n",
    "              [0.10, 'rgb(253,174,97)'], [0.25, 'rgb(213,62,79)'], [1.0, 'rgb(158,1,66)']]\n",
    "\n",
    "data = [ dict(\n",
    "        type = 'choropleth',\n",
    "        autocolorscale = False,\n",
    "        colorscale = colorscale,\n",
    "        showscale = True,\n",
    "        locations = train[\"country\"].value_counts().index,\n",
    "        locationmode = 'country names',\n",
    "        z = train[\"country\"].value_counts().values,\n",
    "        marker = dict(\n",
    "            line = dict(color = 'rgb(250,250,225)', width = 1)),\n",
    "            colorbar = dict( title = 'Customer Visits ')\n",
    "            ) \n",
    "       ]\n",
    "\n",
    "layout = dict(\n",
    "    height=600,\n",
    "    title = 'Distribution mondiale des visites clients',\n",
    "    geo = dict(\n",
    "        showframe = True,\n",
    "        showocean = True,\n",
    "        oceancolor = 'rgb(28,107,160)',\n",
    "        projection = dict(\n",
    "        type = 'orthographic',\n",
    "            rotation = dict(\n",
    "                    lon = 50,\n",
    "                    lat = 10),\n",
    "        ),\n",
    "        lonaxis =  dict(\n",
    "                showgrid = True,\n",
    "                gridcolor = 'rgb(12, 102, 102)'\n",
    "            ),\n",
    "        lataxis = dict(\n",
    "                showgrid = True,\n",
    "                gridcolor = 'rgb(12, 102, 102)'\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir sur le graph que les plus grandes visites se font aux USA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Channel: The channel via which the user came to the Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.channelGrouping.value_counts().plot(kind=\"bar\",title=\"channelGrouping distribution\",figsize=(8,8),rot=25,colormap='Paired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp = train[\"channelGrouping\"].value_counts()\n",
    "colors = [\"#8d44fc\", \"#ed95d5\", \"#caadf7\", \"#6161b7\", \"#7e7eba\", \"#babad1\"]\n",
    "trace = go.Pie(labels=tmp.index, values=tmp.values, marker=dict(colors=colors))\n",
    "layout = go.Layout(title=\"Channel Grouping\", height=400)\n",
    "fig = go.Figure(data = [trace], layout = layout)\n",
    "iplot(fig, filename='basic_pie_chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert date to year, month and day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train['date'] = pd.to_datetime((train['date']).astype(str), format = '%Y-%m-%d')\n",
    "train[['year', 'month', 'day']] = train['date'].astype(str).str.split('-', expand = True)    \n",
    "train.drop('date', axis =1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test['date'] = pd.to_datetime((test['date']).astype(str), format = '%Y-%m-%d')\n",
    "test[['year', 'month', 'day']] = test['date'].astype(str).str.split('-', expand = True)    \n",
    "test.drop('date', axis =1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tools.make_subplots(rows=1, cols=3, subplot_titles=[\"Visites par mois\", \"Visites par jour du mois\"], print_grid=False)\n",
    "trs = []\n",
    "for i,col in enumerate([\"month\", \"day\"]):\n",
    "    t = train[col].value_counts()\n",
    "    tr = go.Bar(x = t.index, marker=dict(color=colors[i]), y = t.values)\n",
    "    trs.append(tr)\n",
    "\n",
    "fig.append_trace(trs[0], 1, 1)\n",
    "fig.append_trace(trs[1], 1, 2)\n",
    "fig['layout'].update(height=400, showlegend=False)\n",
    "iplot(fig)\n",
    "\n",
    "\n",
    "\n",
    "tmp1 = train.groupby('month').agg({\"transactionRevenue\" : \"mean\"}).reset_index()\n",
    "tmp2 = train.groupby('day').agg({\"transactionRevenue\" : \"mean\"}).reset_index()\n",
    "\n",
    "fig = tools.make_subplots(rows=1, cols=3, subplot_titles=[\"Revenu moyen par mois\", \"Revenu moyen par jour du mois\"], print_grid=False)\n",
    "tr1 = go.Bar(x = tmp1.month, marker=dict(color=\"red\", opacity=0.5), y = tmp1.transactionRevenue)\n",
    "tr2 = go.Bar(x = tmp2.day, marker=dict(color=\"orange\", opacity=0.5), y = tmp2.transactionRevenue)\n",
    "fig.append_trace(tr1, 1, 1)\n",
    "fig.append_trace(tr2, 1, 2)\n",
    "fig['layout'].update(height=400, showlegend=False)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fréquence des visites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn = train[\"visitNumber\"].value_counts()\n",
    "def vn_bins(x):\n",
    "    if x == 1:\n",
    "        return \"1\" \n",
    "    elif x < 5:\n",
    "        return \"2-5\"\n",
    "    elif x < 10:\n",
    "        return \"5-10\"\n",
    "    elif x < 50:\n",
    "        return \"10-50\"\n",
    "    elif x < 100:\n",
    "        return \"50-100\"\n",
    "    else:\n",
    "        return \"100+\"\n",
    "    \n",
    "vn = train[\"visitNumber\"].apply(vn_bins).value_counts()\n",
    "\n",
    "trace1 = go.Bar(y = vn.index[::-1], orientation=\"h\" , x = vn.values[::-1], marker=dict(color=\"#7af9ad\"))\n",
    "layout = go.Layout(title=\"Distribution du nombre de visites\", \n",
    "                   xaxis=dict(title=\"Frequence\"),yaxis=dict(title=\"Nombre de visites\") ,\n",
    "                   height=400, margin=dict(l=300, r=300))\n",
    "figure = go.Figure(data = [trace1], layout = layout)\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero = train[train[\"transactionRevenue\"] > 0][\"transactionRevenue\"]\n",
    "print (\"Il y a  \" + str(len(non_zero)) + \" visiteurs du train dataset ayant des revenus de transaction totaux non nuls\")\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.distplot(non_zero)\n",
    "plt.title(\"Répartition des transactions totales non nulles\");\n",
    "plt.xlabel(\"Total Transactions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11515 visitors in the train dataset having non zero total transaction revenue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.distplot(np.log1p(non_zero))\n",
    "plt.title(\"Log - Répartition des transactions totales non nulle\");\n",
    "plt.xlabel(\"Log - Total Transactions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attributs du profil d'un visiteur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "agg_dict = {}\n",
    "for col in [\"bounces\", \"hits\", \"newVisits\", \"pageviews\", \"transactionRevenue\"]:\n",
    "    train[col] = train[col].astype('float')\n",
    "    agg_dict[col] = \"sum\"\n",
    "tmp = train.groupby(\"fullVisitorId\").agg(agg_dict).reset_index()\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbin_hits(x):\n",
    "    if x < 5:\n",
    "        return \"1-5\"\n",
    "    elif x < 10:\n",
    "        return \"5-10\"\n",
    "    elif x < 30:\n",
    "        return \"10-30\"\n",
    "    elif x < 50:\n",
    "        return \"30-50\"\n",
    "    elif x < 100:\n",
    "        return \"50-100\"\n",
    "    else:\n",
    "        return \"100+\"\n",
    "\n",
    "    \n",
    "#[\"bounces\", \"hits\", \"newVisits\", \"pageviews\", \"transactionRevenue\"]:\n",
    "    \n",
    "    \n",
    "tmp[\"total_hits_bin\"] = tmp[\"hits\"].apply(getbin_hits)\n",
    "tmp[\"totals_bounces_bin\"] = tmp[\"bounces\"].apply(lambda x : str(x) if x <= 5 else \"5+\")\n",
    "tmp[\"totals_pageviews_bin\"] = tmp[\"pageviews\"].apply(lambda x : str(x) if x <= 50 else \"50+\")\n",
    "\n",
    "t1 = tmp[\"total_hits_bin\"].value_counts()\n",
    "t2 = tmp[\"totals_bounces_bin\"].value_counts()\n",
    "t3 = tmp[\"newVisits\"].value_counts()\n",
    "t4 = tmp[\"totals_pageviews_bin\"].value_counts()\n",
    "\n",
    "fig = tools.make_subplots(rows=2, cols=2, subplot_titles=[\"Nombre total de visites par utilisateur\", \"Total de rebonds par utilisateur\", \n",
    "                                                         \"Nombre total de NewVistits par utilisateur\", \"Nombre total de pages vues par utilisateur\"], print_grid=False)\n",
    "\n",
    "tr1 = go.Bar(x = t1.index[:20], y = t1.values[:20])\n",
    "tr2 = go.Bar(x = t2.index[:20], y = t2.values[:20])\n",
    "tr3 = go.Bar(x = t3.index[:20], y = t3.values[:20])\n",
    "tr4 = go.Bar(x = t4.index, y = t4.values)\n",
    "\n",
    "fig.append_trace(tr1, 1, 1)\n",
    "fig.append_trace(tr2, 1, 2)\n",
    "fig.append_trace(tr3, 2, 1)\n",
    "fig.append_trace(tr4, 2, 2)\n",
    "\n",
    "fig['layout'].update(height=700, showlegend=False)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Identifions quelles colonnes peuvent être supprimées.\n",
    "- Supression des colonnes avec des valeurs nulles\n",
    "- Suppression des identifiants et autres colonnes non pertinentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supression de toutes les colonnes qui ont toutes les valeurs nulles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#les hits et les pages vues sont les seules valeurs numériques, convertissons-les en objet numpy\n",
    "train[\"hits\"].fillna(0, inplace=True)\n",
    "train[\"hits\"] = train[\"hits\"].astype('float')\n",
    "train[\"pageviews\"].fillna(0, inplace=True)\n",
    "train[\"pageviews\"] = train[\"pageviews\"].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"hits\"].fillna(0, inplace=True)\n",
    "test[\"hits\"] = train[\"hits\"].astype('float')\n",
    "test[\"pageviews\"].fillna(0, inplace=True)\n",
    "test[\"pageviews\"] = train[\"pageviews\"].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape,test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application du natural log sur transactionRevenue ce qui donne transactionRevenue_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"transactionRevenue\"].fillna(0, inplace=True)\n",
    "train[\"transactionRevenue\"] = train[\"transactionRevenue\"].astype('float')\n",
    "train['transactionRevenue_log'] = np.log(train[train['transactionRevenue'] > 0][\"transactionRevenue\"] + 0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copions le  dataframe dans des dataframes temporaires pour construire notre modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train.copy()\n",
    "test_dataset = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable à predire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_dataset['transactionRevenue_log'].fillna(0)\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppression des colonnes qui n'aident pas au training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.drop('fullVisitorId', axis=1, inplace=True)\n",
    "train_dataset.drop('sessionId', axis=1, inplace=True)\n",
    "train_dataset.drop('transactionRevenue', axis=1, inplace=True)\n",
    "train_dataset.drop('visitId', axis=1, inplace=True)\n",
    "train_dataset.drop('visitStartTime', axis=1, inplace=True)\n",
    "train_dataset.drop('transactionRevenue_log', axis=1, inplace=True)\n",
    "train_dataset.drop('visits', axis=1, inplace=True)\n",
    "train_dataset.drop('visitNumber', axis=1, inplace=True)\n",
    "train_dataset.drop('isTrueDirect', axis=1, inplace=True)\n",
    "train_dataset.drop('adContent', axis=1, inplace=True)\n",
    "train_dataset.drop('networkDomain', axis=1, inplace=True)\n",
    "train_dataset.drop('isVideoAd', axis=1, inplace=True)\n",
    "train_dataset.drop('gclId', axis=1, inplace=True)\n",
    "train_dataset.drop('slot', axis=1, inplace=True)\n",
    "train_dataset.drop('adNetworkType', axis=1, inplace=True)\n",
    "train_dataset.drop('keyword', axis=1, inplace=True)\n",
    "train_dataset.drop('referralPath', axis=1, inplace=True)\n",
    "train_dataset.drop('page', axis=1, inplace=True)\n",
    "train_dataset.drop('campaignCode', axis=1, inplace=True)\n",
    "train_dataset.drop('newVisits', axis=1, inplace=True)\n",
    "train_dataset.drop('bounces', axis=1, inplace=True)\n",
    "train_dataset.drop('targetingCriteria', axis=1, inplace=True)\n",
    "train_dataset.drop('socialEngagementType', axis=1, inplace=True)\n",
    "train_dataset.drop('browserSize', axis=1, inplace=True)\n",
    "train_dataset.drop('browserVersion', axis=1, inplace=True)\n",
    "train_dataset.drop('flashVersion', axis=1, inplace=True)\n",
    "train_dataset.drop('language', axis=1, inplace=True)\n",
    "train_dataset.drop('mobileDeviceBranding', axis=1, inplace=True)\n",
    "train_dataset.drop('mobileDeviceInfo', axis=1, inplace=True)\n",
    "train_dataset.drop('mobileDeviceMarketingName', axis=1, inplace=True)\n",
    "train_dataset.drop('mobileDeviceModel', axis=1, inplace=True)\n",
    "train_dataset.drop('mobileInputSelector', axis=1, inplace=True)\n",
    "train_dataset.drop('operatingSystemVersion', axis=1, inplace=True)\n",
    "train_dataset.drop('screenColors', axis=1, inplace=True)\n",
    "train_dataset.drop('screenResolution', axis=1, inplace=True)\n",
    "train_dataset.drop('cityId', axis=1, inplace=True)\n",
    "train_dataset.drop('longitude', axis=1, inplace=True)\n",
    "train_dataset.drop('latitude', axis=1, inplace=True)\n",
    "train_dataset.drop('networkLocation', axis=1, inplace=True)\n",
    "train_dataset.drop('criteriaParameters', axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppression des colonnes qui n'aident pas au test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.drop('fullVisitorId', axis=1, inplace=True)\n",
    "test_dataset.drop('sessionId', axis=1, inplace=True)\n",
    "test_dataset.drop('visitId', axis=1, inplace=True)\n",
    "test_dataset.drop('visitStartTime', axis=1, inplace=True)\n",
    "test_dataset.drop('visits', axis=1, inplace=True)\n",
    "test_dataset.drop('visitNumber', axis=1, inplace=True)\n",
    "test_dataset.drop('isTrueDirect', axis=1, inplace=True)\n",
    "test_dataset.drop('adContent', axis=1, inplace=True)\n",
    "test_dataset.drop('networkDomain', axis=1, inplace=True)\n",
    "test_dataset.drop('isVideoAd', axis=1, inplace=True)\n",
    "test_dataset.drop('gclId', axis=1, inplace=True)\n",
    "test_dataset.drop('slot', axis=1, inplace=True)\n",
    "test_dataset.drop('adNetworkType', axis=1, inplace=True)\n",
    "test_dataset.drop('keyword', axis=1, inplace=True)\n",
    "test_dataset.drop('referralPath', axis=1, inplace=True)\n",
    "test_dataset.drop('page', axis=1, inplace=True)\n",
    "test_dataset.drop('newVisits', axis=1, inplace=True)\n",
    "test_dataset.drop('bounces', axis=1, inplace=True)\n",
    "test_dataset.drop('targetingCriteria', axis=1, inplace=True)\n",
    "test_dataset.drop('socialEngagementType', axis=1, inplace=True)\n",
    "test_dataset.drop('browserSize', axis=1, inplace=True)\n",
    "test_dataset.drop('browserVersion', axis=1, inplace=True)\n",
    "test_dataset.drop('flashVersion', axis=1, inplace=True)\n",
    "test_dataset.drop('language', axis=1, inplace=True)\n",
    "test_dataset.drop('mobileDeviceBranding', axis=1, inplace=True)\n",
    "test_dataset.drop('mobileDeviceInfo', axis=1, inplace=True)\n",
    "test_dataset.drop('mobileDeviceMarketingName', axis=1, inplace=True)\n",
    "test_dataset.drop('mobileDeviceModel', axis=1, inplace=True)\n",
    "test_dataset.drop('mobileInputSelector', axis=1, inplace=True)\n",
    "test_dataset.drop('operatingSystemVersion', axis=1, inplace=True)\n",
    "test_dataset.drop('screenColors', axis=1, inplace=True)\n",
    "test_dataset.drop('screenResolution', axis=1, inplace=True)\n",
    "test_dataset.drop('cityId', axis=1, inplace=True)\n",
    "test_dataset.drop('longitude', axis=1, inplace=True)\n",
    "test_dataset.drop('latitude', axis=1, inplace=True)\n",
    "test_dataset.drop('networkLocation', axis=1, inplace=True)\n",
    "test_dataset.drop('criteriaParameters', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regardons les variables catégorielles que l'on va devoir changer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_train_dataset = train_dataset.select_dtypes(include=[np.object])\n",
    "categorical_features_train_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***to convert string categorical values to numerical values***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "train_dataset['channelGrouping'] = labelencoder_X.fit_transform(train_dataset['channelGrouping'])\n",
    "train_dataset['campaign'] = labelencoder_X.fit_transform(train_dataset['campaign'])\n",
    "train_dataset['medium'] = labelencoder_X.fit_transform(train_dataset['medium'])\n",
    "train_dataset['source'] = labelencoder_X.fit_transform(train_dataset['source'])\n",
    "train_dataset['browser'] = labelencoder_X.fit_transform(train_dataset['browser'])\n",
    "train_dataset['deviceCategory'] = labelencoder_X.fit_transform(train_dataset['deviceCategory'])\n",
    "train_dataset['isMobile'] = labelencoder_X.fit_transform(train_dataset['isMobile'])\n",
    "train_dataset['operatingSystem'] = labelencoder_X.fit_transform(train_dataset['operatingSystem'])\n",
    "train_dataset['city'] = labelencoder_X.fit_transform(train_dataset['city'])\n",
    "train_dataset['continent'] = labelencoder_X.fit_transform(train_dataset['continent'])\n",
    "train_dataset['country'] = labelencoder_X.fit_transform(train_dataset['country'])\n",
    "train_dataset['metro'] = labelencoder_X.fit_transform(train_dataset['metro'])\n",
    "train_dataset['region'] = labelencoder_X.fit_transform(train_dataset['region'])\n",
    "train_dataset['subContinent'] = labelencoder_X.fit_transform(train_dataset['subContinent'])\n",
    "train_dataset['year'] = labelencoder_X.fit_transform(train_dataset['year'])\n",
    "train_dataset['month'] = labelencoder_X.fit_transform(train_dataset['month'])\n",
    "train_dataset['day'] = labelencoder_X.fit_transform(train_dataset['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset['channelGrouping'] = labelencoder_X.fit_transform(test_dataset['channelGrouping'])\n",
    "test_dataset['campaign'] = labelencoder_X.fit_transform(test_dataset['campaign'])\n",
    "test_dataset['medium'] = labelencoder_X.fit_transform(test_dataset['medium'])\n",
    "test_dataset['source'] = labelencoder_X.fit_transform(test_dataset['source'])\n",
    "test_dataset['browser'] = labelencoder_X.fit_transform(test_dataset['browser'])\n",
    "test_dataset['deviceCategory'] = labelencoder_X.fit_transform(test_dataset['deviceCategory'])\n",
    "test_dataset['isMobile'] = labelencoder_X.fit_transform(test_dataset['isMobile'])\n",
    "test_dataset['operatingSystem'] = labelencoder_X.fit_transform(test_dataset['operatingSystem'])\n",
    "test_dataset['city'] = labelencoder_X.fit_transform(test_dataset['city'])\n",
    "test_dataset['continent'] = labelencoder_X.fit_transform(test_dataset['continent'])\n",
    "test_dataset['country'] = labelencoder_X.fit_transform(test_dataset['country'])\n",
    "test_dataset['metro'] = labelencoder_X.fit_transform(test_dataset['metro'])\n",
    "test_dataset['region'] = labelencoder_X.fit_transform(test_dataset['region'])\n",
    "test_dataset['subContinent'] = labelencoder_X.fit_transform(test_dataset['subContinent'])\n",
    "test_dataset['year'] = labelencoder_X.fit_transform(test_dataset['year'])\n",
    "test_dataset['month'] = labelencoder_X.fit_transform(test_dataset['month'])\n",
    "test_dataset['day'] = labelencoder_X.fit_transform(test_dataset['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset.shape, test_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corelation_train = train_dataset.corr() \n",
    "sns.heatmap(corelation_train, square = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corelation_test = test_dataset.corr() \n",
    "sns.heatmap(corelation_test, square = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(train_dataset ,y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premier modèle : Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deuxième modèle : XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost est une bibliothèque optimisée de renforcement de gradient distribué conçue pour être très efficace, flexible et portable. Il implémente des algorithmes d'apprentissage automatique dans le cadre du Gradient Boosting. XGBoost fournit un boosting d'arbre parallèle (également connu sous le nom de GBDT, GBM) qui résout de nombreux problèmes de science des données de manière rapide et précise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_model = XGBRegressor()\n",
    "XGB_model.fit(X_train, Y_train, eval_metric='rmse',verbose=130)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troisième modèle : Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "RF_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quatrième modèle : LGBMRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LGB_model = lgb.LGBMRegressor()\n",
    "LGB_model.fit(X_train, Y_train, eval_metric='rmse', verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_XGB = XGB_model.predict(X_test)\n",
    "y_pred_LGB = LGB_model.predict(X_test)\n",
    "y_pred_rf = RF_model.predict(X_test)\n",
    "y_pred_lr = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remplacons les valeurs negatives avec 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_XGB[y_pred_XGB < 0] =0\n",
    "y_pred_XGB\n",
    "y_pred_LGB[y_pred_LGB < 0] =0\n",
    "y_pred_LGB\n",
    "y_pred_rf[y_pred_rf < 0] =0\n",
    "y_pred_rf\n",
    "y_pred_lr[y_pred_lr < 0] =0\n",
    "y_pred_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test, y_pred_lr)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test, y_pred_XGB)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test, y_pred_LGB)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y_test, y_pred_rf )\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation des modèles utilisant le root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"LinReg: sqrt  \", math.sqrt(mean_squared_error(Y_test, y_pred_lr)))\n",
    "print(\"XGBoost: sqrt  \", math.sqrt(mean_squared_error(Y_test, y_pred_XGB)))\n",
    "print(\"LGB: sqrt  \", math.sqrt(mean_squared_error(Y_test, y_pred_LGB)))\n",
    "print(\"RandomForest: sqrt  \",math.sqrt(mean_squared_error(Y_test, y_pred_rf) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenons donc LGB car c'est lui qui nous donne le plus petit MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result= LGB_model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons maintenant les caractéristiques importantes du modèle light gbm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "lgb.plot_importance(LGB_model, max_num_features=50, height=0.8, ax=ax)\n",
    "ax.grid(False)\n",
    "plt.title(\"Feature Important - LightGBM\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définissons toutes les valeurs négatives sur 0\n",
    "final_result[final_result < 0] =0\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullVisitorId_1 = test['fullVisitorId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier_csv = pd.DataFrame({'fullVisitorId': fullVisitorId_1,'PredictedLogRevenue':final_result},columns=['fullVisitorId','PredictedLogRevenue'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fichier_csv.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier_csv = fichier_csv.groupby('fullVisitorId').sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier_csv.to_csv(r\"resultat_final.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
