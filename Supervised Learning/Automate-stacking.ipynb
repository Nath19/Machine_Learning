{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from vecstack import stacking\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>12.72</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.20</td>\n",
       "      <td>18.8</td>\n",
       "      <td>86</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.77</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.16</td>\n",
       "      <td>3.14</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>13.11</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.70</td>\n",
       "      <td>15.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.28</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.18</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>11.76</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.92</td>\n",
       "      <td>20.0</td>\n",
       "      <td>103</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.50</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>13.05</td>\n",
       "      <td>3.86</td>\n",
       "      <td>2.32</td>\n",
       "      <td>22.5</td>\n",
       "      <td>85</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.01</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>3</td>\n",
       "      <td>13.11</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.75</td>\n",
       "      <td>25.5</td>\n",
       "      <td>116</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.33</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "81       2    12.72        1.81  2.20               18.8         86   \n",
       "66       2    13.11        1.01  1.70               15.0         78   \n",
       "112      2    11.76        2.68  2.92               20.0        103   \n",
       "83       2    13.05        3.86  2.32               22.5         85   \n",
       "152      3    13.11        1.90  2.75               25.5        116   \n",
       "\n",
       "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "81            2.20        2.53                  0.26             1.77   \n",
       "66            2.98        3.18                  0.26             2.28   \n",
       "112           1.75        2.03                  0.60             1.05   \n",
       "83            1.65        1.59                  0.61             1.62   \n",
       "152           2.20        1.28                  0.26             1.56   \n",
       "\n",
       "     Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "81               3.9  1.16                          3.14      714  \n",
       "66               5.3  1.12                          3.18      502  \n",
       "112              3.8  1.23                          2.50      607  \n",
       "83               4.8  0.84                          2.01      515  \n",
       "152              7.1  0.61                          1.33      425  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "names = ['Class', 'Alcohol', 'Malic acid', 'Ash',\n",
    "         'Alcalinity of ash' ,'Magnesium', 'Total phenols',\n",
    "         'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',     'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',\n",
    "         'Proline']\n",
    "df = pd.read_csv(link, header=None, names=names)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    71\n",
       "1    59\n",
       "3    48\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['Class']]\n",
    "X = df.iloc[:,1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    KNeighborsClassifier(n_neighbors=5,\n",
    "                        n_jobs=-1),\n",
    "        \n",
    "    RandomForestClassifier(random_state=0, n_jobs=-1, \n",
    "                           n_estimators=100, max_depth=3),\n",
    "        \n",
    "    XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
    "                  n_estimators=100, max_depth=3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    \"\"\"ROC AUC metric for both binary and multiclass classification.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : 1d numpy array\n",
    "        True class labels\n",
    "    y_pred : 2d numpy array\n",
    "        Predicted probabilities for each class\n",
    "    \"\"\"\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    y_true = ohe.fit_transform(y_true.reshape(-1, 1))\n",
    "    auc_score = roc_auc_score(y_true, y_pred)\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " using first level models to make predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NAMAR\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [3]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [KNeighborsClassifier]\n",
      "    fold  0:  [0.69444444]\n",
      "    fold  1:  [0.63888889]\n",
      "    fold  2:  [0.62857143]\n",
      "    fold  3:  [0.65714286]\n",
      "    ----\n",
      "    MEAN:     [0.65476190] + [0.02509117]\n",
      "    FULL:     [0.65492958]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n",
      "    fold  0:  [0.97222222]\n",
      "    fold  1:  [0.97222222]\n",
      "    fold  2:  [0.97142857]\n",
      "    fold  3:  [1.00000000]\n",
      "    ----\n",
      "    MEAN:     [0.97896825] + [0.01214701]\n",
      "    FULL:     [0.97887324]\n",
      "\n",
      "model  2:     [XGBClassifier]\n",
      "    fold  0:  [0.94444444]\n",
      "    fold  1:  [0.94444444]\n",
      "    fold  2:  [0.97142857]\n",
      "    fold  3:  [1.00000000]\n",
      "    ----\n",
      "    MEAN:     [0.96507937] + [0.02297479]\n",
      "    FULL:     [0.96478873]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S_train, S_test = stacking(models,                   \n",
    "                           X_train, y_train, X_test,   \n",
    "                           regression=False, \n",
    "     \n",
    "                           mode='oof_pred_bag', \n",
    "       \n",
    "                           needs_proba=False,\n",
    "         \n",
    "                           save_dir=None, \n",
    "            \n",
    "                           metric=accuracy_score, \n",
    "    \n",
    "                           n_folds=4, \n",
    "                 \n",
    "                           stratified=True,\n",
    "            \n",
    "                           shuffle=True,  \n",
    "            \n",
    "                           random_state=0,    \n",
    "         \n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stacking function takes several inputs:\n",
    "- models: the first level models we defined earlier\n",
    "- X_train, y_train, X_test: our data\n",
    "- regression: Boolean indicating whether we want to use the function for regression. In our case set to False since this is a classification\n",
    "- mode: using the earlier describe out-of-fold during cross-validation\n",
    "- needs_proba: Boolean indicating whether you need the probabilities of class labels\n",
    "- save_dir: save the result to directory Boolean\n",
    "- metric: what evaluation metric to use (we imported the accuracy_score in the beginning)\n",
    "- n_folds: how many folds to use for cross-validation\n",
    "- stratified: whether to use stratified cross-validation\n",
    "- shuffle: whether to shuffle the data\n",
    "- random_state: setting a random state for reproducibility\n",
    "- verbose: 2 here refers to printing all info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ll that’s left to do now is fit the second level model(s) of our choice on our predictions to make our final predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we are going to use an XGBoost Classifier. This step is not significantly different from a regular fit-and-predict in sklearn except for the fact that instead of using X_train to train our model, we are using our predictions S_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score: [0.94444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NAMAR\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\NAMAR\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
    "                      n_estimators=100, max_depth=3)\n",
    "    \n",
    "model = model.fit(S_train, y_train)\n",
    "y_pred = model.predict(S_test)\n",
    "print('Final prediction score: [%.8f]' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using vecstacks’ stacking automation, we’ve managed to predict the correct wine cultivar with an accuracy of approximately 94.4%!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
